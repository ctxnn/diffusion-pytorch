{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DIFFUSION - MNIST"
      ],
      "metadata": {
        "id": "dO9FA3fBfuhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepinv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sR4yw4mf4Zf",
        "outputId": "b50424de-6a92-4004-e908-da64660d61f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepinv\n",
            "  Downloading deepinv-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepinv) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from deepinv) (3.10.0)\n",
            "Collecting hdf5storage (from deepinv)\n",
            "  Downloading hdf5storage-0.2.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepinv) (4.67.1)\n",
            "Requirement already satisfied: torch<2.7 in /usr/local/lib/python3.11/dist-packages (from deepinv) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from deepinv) (0.21.0+cu124)\n",
            "Collecting torchmetrics (from deepinv)\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepinv) (0.8.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from deepinv) (0.20.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from deepinv) (1.15.3)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.11/dist-packages (from deepinv) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7->deepinv)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7->deepinv) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7->deepinv) (1.3.0)\n",
            "Requirement already satisfied: h5py>=3.9 in /usr/local/lib/python3.11/dist-packages (from hdf5storage->deepinv) (3.14.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepinv) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepinv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepinv) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepinv) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepinv) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepinv) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepinv) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->deepinv) (2.9.0.post0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->deepinv)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (8.2.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (2.11.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (2.32.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->deepinv) (1.3.6)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->deepinv) (4.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics->deepinv) (75.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->deepinv) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->deepinv) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->deepinv) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->deepinv) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->deepinv) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->deepinv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->deepinv) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->deepinv) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.7->deepinv) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->deepinv) (5.0.2)\n",
            "Downloading deepinv-0.3.2-py3-none-any.whl (689 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.9/689.9 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hdf5storage-0.2.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hdf5storage, nvidia-cusolver-cu12, torchmetrics, deepinv\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed deepinv-0.3.2 hdf5storage-0.2.0 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## TRAINING\n",
        "\n"
      ],
      "metadata": {
        "id": "yfQWluQnfsUX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zELhUFRdv_z",
        "outputId": "d9b0a267-b104-4588-8e3c-434c33f2c3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.5614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/100], Loss: 0.0886\n",
            "Epoch [3/100], Loss: 0.0401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/100], Loss: 0.0354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/100], Loss: 0.0347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/100], Loss: 0.0267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/100], Loss: 0.0278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/100], Loss: 0.0292\n",
            "Epoch [9/100], Loss: 0.0282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.0248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/100], Loss: 0.0249\n",
            "Epoch [12/100], Loss: 0.0275\n",
            "Epoch [13/100], Loss: 0.0266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/100], Loss: 0.0244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/100], Loss: 0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [16/100], Loss: 0.0234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [17/100], Loss: 0.0246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [18/100], Loss: 0.0233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [19/100], Loss: 0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/100], Loss: 0.0202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [21/100], Loss: 0.0235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [22/100], Loss: 0.0230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [23/100], Loss: 0.0218\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [24/100], Loss: 0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [25/100], Loss: 0.0214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [26/100], Loss: 0.0212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [27/100], Loss: 0.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/100], Loss: 0.0210\n",
            "Epoch [29/100], Loss: 0.0199\n",
            "Epoch [30/100], Loss: 0.0205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [31/100], Loss: 0.0199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [32/100], Loss: 0.0201\n",
            "Epoch [33/100], Loss: 0.0202\n",
            "Epoch [34/100], Loss: 0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [35/100], Loss: 0.0222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [36/100], Loss: 0.0214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [37/100], Loss: 0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [38/100], Loss: 0.0210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [39/100], Loss: 0.0183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [40/100], Loss: 0.0194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [41/100], Loss: 0.0194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [42/100], Loss: 0.0208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [43/100], Loss: 0.0193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [44/100], Loss: 0.0201\n",
            "Epoch [45/100], Loss: 0.0216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [46/100], Loss: 0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [47/100], Loss: 0.0193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [48/100], Loss: 0.0202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [49/100], Loss: 0.0188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [50/100], Loss: 0.0192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [51/100], Loss: 0.0170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [52/100], Loss: 0.0193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [53/100], Loss: 0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [54/100], Loss: 0.0183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [55/100], Loss: 0.0179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [56/100], Loss: 0.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [57/100], Loss: 0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [58/100], Loss: 0.0192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [59/100], Loss: 0.0184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [60/100], Loss: 0.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [61/100], Loss: 0.0210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [62/100], Loss: 0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [63/100], Loss: 0.0183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [64/100], Loss: 0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [65/100], Loss: 0.0217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [66/100], Loss: 0.0191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [67/100], Loss: 0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [68/100], Loss: 0.0202\n",
            "Epoch [69/100], Loss: 0.0204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [70/100], Loss: 0.0174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [71/100], Loss: 0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [72/100], Loss: 0.0178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [73/100], Loss: 0.0153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [74/100], Loss: 0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [75/100], Loss: 0.0180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [76/100], Loss: 0.0185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [77/100], Loss: 0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [78/100], Loss: 0.0183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [79/100], Loss: 0.0170\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [80/100], Loss: 0.0162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [81/100], Loss: 0.0171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [82/100], Loss: 0.0162\n",
            "Epoch [83/100], Loss: 0.0156\n",
            "Epoch [84/100], Loss: 0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [85/100], Loss: 0.0168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [86/100], Loss: 0.0180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [87/100], Loss: 0.0186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [88/100], Loss: 0.0151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [89/100], Loss: 0.0156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [90/100], Loss: 0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [91/100], Loss: 0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [92/100], Loss: 0.0187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [93/100], Loss: 0.0180\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [94/100], Loss: 0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [95/100], Loss: 0.0193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [96/100], Loss: 0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [97/100], Loss: 0.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [98/100], Loss: 0.0167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [99/100], Loss: 0.0184\n",
            "Epoch [100/100], Loss: 0.0176\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from deepinv.models.diffunet import DiffUNet\n",
        "import os\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Set hyperparameters\n",
        "    batch_size = 32\n",
        "    num_epochs = 100\n",
        "    lr = 1e-4\n",
        "    image_size = 32  # MNIST is 28x28, but we'll resize to 32x32 for the model\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5,), (0.5,)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=\"./data\", train=True, download=True, transform=transform\n",
        "    )\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
        "    )\n",
        "\n",
        "    # Limit the dataset to 100 images\n",
        "    num_img = 1000\n",
        "    indices = torch.arange(num_img)\n",
        "    train_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    model = DiffUNet(\n",
        "        in_channels=1, out_channels=1, pretrained=None  # MNIST is grayscale\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Define DDPM constants\n",
        "    timesteps = 1000  # Total number of diffusion steps\n",
        "    beta_start = 1e-4  # Starting value for noise schedule\n",
        "    beta_end = 0.02  # Ending value for noise schedule\n",
        "\n",
        "    # Linear noise schedule\n",
        "    betas = torch.linspace(beta_start, beta_end, timesteps, device=device)\n",
        "    alphas = 1.0 - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "    alphas_cumprod_prev = torch.cat(\n",
        "        [torch.tensor([1.0], device=device), alphas_cumprod[:-1]]\n",
        "    )\n",
        "    sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
        "    posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "\n",
        "    # Training loop\n",
        "    # Create a list to store all losses\n",
        "    all_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        epoch_losses = []  # Store losses for this epoch\n",
        "\n",
        "        for batch_idx, (images, _) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Sample random timesteps\n",
        "            t = torch.randint(0, timesteps, (images.shape[0],), device=device)\n",
        "\n",
        "            # Sample noise\n",
        "            noise = torch.randn_like(images)\n",
        "\n",
        "            # Apply forward diffusion process at timestep t\n",
        "            noised_images = (\n",
        "                sqrt_alphas_cumprod[t, None, None, None] * images\n",
        "                + sqrt_one_minus_alphas_cumprod[t, None, None, None] * noise\n",
        "            )\n",
        "\n",
        "            # Predict noise\n",
        "            noise_pred = model(noised_images, t, type_t=\"timestep\")\n",
        "\n",
        "            # Calculate loss (the model predicts the noise that was added)\n",
        "            loss = nn.MSELoss()(noise_pred, noise)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Save the loss value\n",
        "            loss_value = loss.item()\n",
        "            total_loss += loss_value\n",
        "            epoch_losses.append(loss_value)\n",
        "\n",
        "        # Save all losses from this epoch\n",
        "        # Create directories if they don't exist\n",
        "        os.makedirs(\"./losses\", exist_ok=True)\n",
        "        os.makedirs(\"./weights\", exist_ok=True)\n",
        "        os.makedirs(\"./img/noised\", exist_ok=True)\n",
        "        os.makedirs(\"./img/denoised\", exist_ok=True)\n",
        "        os.makedirs(\"./img/original\", exist_ok=True)\n",
        "\n",
        "        all_losses.extend(epoch_losses)\n",
        "\n",
        "        # Save the losses list after each epoch\n",
        "        np.save(f\"./losses/losses_epoch_{epoch+1}.npy\", np.array(all_losses))\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "        # Inference on random timesteps for visualizing training progress\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            with torch.no_grad():\n",
        "                # Select a random batch from the training data for visualization\n",
        "                sample_batch, _ = next(iter(train_loader))\n",
        "                sample_batch = sample_batch.to(device)\n",
        "\n",
        "                # Pick a single image from the batch\n",
        "                sample_image = sample_batch[0:1]\n",
        "                # Choose a single random timestep\n",
        "                random_t = torch.randint(\n",
        "                    1, 900, (1,)\n",
        "                ).item()  # Choose a timestep where noise is visible\n",
        "                t_tensor = torch.tensor([random_t], device=device)\n",
        "\n",
        "                # Add noise according to the diffusion process\n",
        "                noised_image = sqrt_alphas_cumprod[\n",
        "                    random_t\n",
        "                ] * sample_image + sqrt_one_minus_alphas_cumprod[\n",
        "                    random_t\n",
        "                ] * torch.randn_like(\n",
        "                    sample_image\n",
        "                )\n",
        "\n",
        "                # Get model prediction (predicted noise)\n",
        "                noise_pred = model(noised_image, t_tensor, type_t=\"timestep\")\n",
        "\n",
        "                # Denoise the image using the model prediction\n",
        "                # x_0 = (x_t - sqrt(1-α_t) * predicted_noise) / sqrt(α_t)\n",
        "                predicted_original = (\n",
        "                    noised_image - sqrt_one_minus_alphas_cumprod[random_t] * noise_pred\n",
        "                ) / sqrt_alphas_cumprod[random_t]\n",
        "\n",
        "                # Clamp values to valid image range\n",
        "                predicted_original = torch.clamp(predicted_original, -1, 1)\n",
        "\n",
        "                # Save original image\n",
        "                plt.figure(figsize=(5, 5))\n",
        "                plt.imshow(sample_image.cpu().squeeze(0).squeeze(0), cmap=\"gray\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.savefig(\n",
        "                    f\"./img/original/epoch_{epoch+1}_original.png\",\n",
        "                    bbox_inches=\"tight\",\n",
        "                    pad_inches=0,\n",
        "                )\n",
        "                plt.close()\n",
        "\n",
        "                # Save noisy image\n",
        "                plt.figure(figsize=(5, 5))\n",
        "                plt.imshow(noised_image.cpu().squeeze(0).squeeze(0), cmap=\"gray\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.savefig(\n",
        "                    f\"./img/noised/epoch_{epoch+1}_noised_t{random_t}.png\",\n",
        "                    bbox_inches=\"tight\",\n",
        "                    pad_inches=0,\n",
        "                )\n",
        "                plt.close()\n",
        "\n",
        "                # Save denoised image\n",
        "                plt.figure(figsize=(5, 5))\n",
        "                plt.imshow(predicted_original.cpu().squeeze(0).squeeze(0), cmap=\"gray\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.savefig(\n",
        "                    f\"./img/denoised/epoch_{epoch+1}_denoised.png\",\n",
        "                    bbox_inches=\"tight\",\n",
        "                    pad_inches=0,\n",
        "                )\n",
        "                plt.close()\n",
        "\n",
        "        # Save model checkpoint\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            torch.save(model.state_dict(), f\"./weights/model_epoch_{epoch + 1}.pth\")\n",
        "\n",
        "    # Save final model\n",
        "    torch.save(model.state_dict(), \"./weights/model_final.pth\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inference"
      ],
      "metadata": {
        "id": "ddHN_NzWfsoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "C69OTJU3ftcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from deepinv.models import DiffUNet\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pretrained model\n",
        "checkpoint_path = \"./weights/model_final.pth\"\n",
        "model = DiffUNet(in_channels=1, out_channels=1, pretrained=Path(checkpoint_path))\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
        "    model.load_state_dict(checkpoint)\n",
        "    print(f\"Loaded model from {checkpoint_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# DDPM parameters\n",
        "num_timesteps = 1000\n",
        "beta_start = 0.0001\n",
        "beta_end = 0.02\n",
        "betas = torch.linspace(beta_start, beta_end, num_timesteps).to(device)\n",
        "alphas = 1.0 - betas\n",
        "alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "\n",
        "def sample_ddpm(model, image_size=32, batch_size=8, channels=1):\n",
        "    \"\"\"Generate samples using DDPM sampling process and return final images.\"\"\"\n",
        "    x = torch.randn(batch_size, channels, image_size, image_size).to(device)\n",
        "\n",
        "    for t in tqdm(reversed(range(num_timesteps)), desc=\"Sampling\"):\n",
        "        t_batch = torch.full((batch_size,), t, dtype=torch.long).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            noise_pred = model(x, t_batch, type_t=\"timestep\")\n",
        "\n",
        "            alpha_t = alphas[t]\n",
        "            alpha_cumprod_t = alphas_cumprod[t]\n",
        "\n",
        "            if t > 0:\n",
        "                noise = torch.randn_like(x)\n",
        "            else:\n",
        "                noise = torch.zeros_like(x)\n",
        "\n",
        "            coef1 = 1.0 / torch.sqrt(alpha_t)\n",
        "            coef2 = (1.0 - alpha_t) / torch.sqrt(1.0 - alpha_cumprod_t)\n",
        "\n",
        "            x = coef1 * (x - coef2 * noise_pred) + torch.sqrt(betas[t]) * noise\n",
        "\n",
        "    x = torch.clamp(x, 0, 1)\n",
        "    return x\n",
        "\n",
        "# Generate and visualize\n",
        "samples = sample_ddpm(model, batch_size=8)\n",
        "\n",
        "# Display as grid\n",
        "grid = make_grid(samples, nrow=4, padding=2, normalize=True)\n",
        "npimg = grid.cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap=\"gray\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "O97Tynkwftxy",
        "outputId": "de63c5f2-9025-4be6-da83-7f4ac0a688f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from ./weights/model_final.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sampling: 1000it [00:39, 25.03it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAFOCAYAAAAWx6x6AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIL9JREFUeJzt3Xm0llX5N/D7MIsCCs6oiSwlTMMVIo4oWpYIoolliVJOOZRJFqxfkC6H0iYycWGmmZkuK4dEUSLTFpDzPCCYIqDlwCSizMN5//i9a73v3vvW53h8njOwP5//vntdz3N2coare+19PXX19fX1BQAA2WjT3BsAAKBpaQABADKjAQQAyIwGEAAgMxpAAIDMaAABADKjAQQAyIwGEAAgMxpAAIDMtGtoYV1dXS33AQDAJ9TQD3jzBBAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMhMu+beAADUSvfu3ZO1pUuXNsNOoGXxBBAAIDMaQACAzGgAAQAyowEEAMiMSyAAtArHHXdckI866qik5qWXXgryAQcckNSMHz8+yK+88koVdgetiyeAAACZ0QACAGRGAwgAkJm6+vr6+gYV1tXVei8AZOozn/lMkK+66qqk5qCDDgryAw88kNRceOGFQX7++eeTmnXr1jVmi9AqNLCt8wQQACA3GkAAgMxoAAEAMqMBBADIjEsgsAkrG5Q7cuTIIHfp0iWp+dvf/hbkSZMmVXdjZG3ChAnJ2ujRo4O8YMGCpOaee+4J8ne+853qboxGi4drF0VRjBo1Ksjt27dPajp37hzkuXPnJjU77LBDkD/1qU8lNatWrQpy2UWfpUuXBvmaa65Jan72s58la62NSyAAAJTSAAIAZEYDCACQGWcAG+Ccc84J8gknnJDUxANJr7322qRm0aJF1d0Ym6wtttgiWTvyyCOD/KUvfSmpGTp0aJDjszONdeeddyZrxx9/fFXem03LmDFjkrV4OPPmm2+e1Lz11ltBLjt3etlll33C3VErDz/8cLK27777Bvm1115LaubMmRPkXr16JTXxkPCVK1cmNfH5wk6dOn34Zv+vDRs2JGvTpk0L8tFHH13xfVoaZwABACilAQQAyIwGEAAgMxpAAIDMtGvuDbQ0119/fbJ22mmnBXnt2rVJTXwAdfny5UnNVVdd9Ql3V65///7J2lNPPVWTr5WzvffeO1nbbbfdgnz44YcnNbvvvnvF995xxx2DvPPOOyc18cDmsqGqtTJgwIBk7Rvf+EaQb7zxxqbZDM3mwQcfTNZ22mmnIPfs2TOpiYf9xgOdi6IojjnmmE+4O5rTgQcemKzFl31WrFhRla/Vpk367CoecB//fiqKojjggAOCXHZR5Igjjgjy5MmTk5rhw4c3ZJstnieAAACZ0QACAGRGAwgAkBmDoCPjxo1L1hoyfHT9+vVBfvvtt5OaeBD0woULk5r4w6rffPPNpCY+UzZw4MCkJh6qesMNNyQ1EydOTNZyEX+Y+A9/+MOkZs899wzytttum9TEZ1w6duyY1Gy55ZZBbtu2bVIT/xiWnXFpiIb8OK9evTrI7dqlR4Hjn/eyD1a/9957g1w2IJ3W7bzzzgvypZdemtTEPwPPPfdcUjN+/PggT506tQq7g48nPqMdf4BDmXnz5iVr8dnvlsYgaAAASmkAAQAyowEEAMiMBhAAIDMGQUfuuuuuZC0eUFo2FDe+BBIP9i2KdGBqLW211VZBPu6445KanC+BDBs2LMgnn3xyUhNflpg9e3ZS07179yD/9re/TWriSzv9+vVLajZs2BDkOXPmJDXxBaEy8cWVOBdFUXTr1q3i+2zcuDHI8X+LoiiKuXPnVnwfWo8+ffoka2eccUaQO3TokNRceeWVQf7+979f1X1BtZQNMo/FFyjiv+2bEk8AAQAyowEEAMiMBhAAIDPOAEZmzZqVrMWDlj/96U8nNfFZsPhDp4uiKPbbb78gH3300UlNPFS1seIzZUuWLKnK+24q4kG0O++8c1Jz3333BXn69Ok13VMtTJo0KVk76aSTgty1a9ekJj4Hs3bt2qTm0Ucf/YS7oznttddeQb7llluSmnj4efy9UxRFceedd1Z3Y9BEygbct2/fPsjxIP9NiSeAAACZ0QACAGRGAwgAkBkNIABAZlwCaYSyIb2xhx9+uGJNr169krV4gPS4ceOSmqOOOqrie7/11ltBvuyyyyq+JifxEOOxY8c2005qa5tttknWOnXqVPF1bdu2DXLZJRAXi1qPnj17JmuTJ08O8q677prUxINzXfhgU1L2ey2+BPLBBx801XaanCeAAACZ0QACAGRGAwgAkBlnAJvRvHnzKq5df/31Sc1hhx0W5M022yypef7554P83HPPNWKHtDa33nprkIcPH57UxGdcyjz00ENBLhsoPXPmzI+5O5rLddddl6zFZ/7KzjZfeOGFtdoSNLkf/OAHQS774IV33nnnI1+zKfEEEAAgMxpAAIDMaAABADKjAQQAyIxLIC3c4YcfnqzFlz5mzZqV1PzmN7+p2Z5oGW655ZZk7Stf+UqQ27RJ/z/eunXrgjxlypSkZsSIEUHeuHFjY7ZIM/n1r38d5LLh8YsXLw7yX//616TmkUceqe7GoIkceuihydoPf/jDIC9fvjypueqqq4J8xx13VHdjLYgngAAAmdEAAgBkRgMIAJCZuvr6+voGFdbV1Xov2TnwwAOTtXiQ7y677JLULFiwIMijR49OasrO89C6PfPMM0Hu27dvUhP/OJf93F577bVB/u53v1uF3dFcRo4cmazF55g6dOiQ1MTnhL///e9Xd2NQJd/85jeDfMQRRyQ1e+65Z5D32muviu97//33J2tHH330x9xdy9PAts4TQACA3GgAAQAyowEEAMiMBhAAIDMugTSjqVOnJmtf+tKXKr7uj3/8Y5BPOeWUqu2J5nHSSScFOR5YWhRF0bNnzyB369YtqVmzZk2QZ8yYkdQceeSRjdkiLdS9996brA0ZMiTITzzxRFITX0Jbv359dTf2Ebp3756sjRs3Lsg33nhjUvPCCy/UakvUwPbbbx/kK6+8Mqn5zGc+E+TevXsnNfElpniYfVEURceOHYMc/y4siqIYM2ZMkCdOnJjUbApcAgEAoJQGEAAgMxpAAIDMtGvuDeRk1KhRQT7ooIMqvmbVqlXJ2uOPP161PVF78dm96667LqkZMGBAkMvOSC1btizIf/7zn5OaE088sRE7pDWJB3cPGjQoqVmyZEmQf/KTnyQ1TXnmr0ePHkG+7bbbkpqBAwcGuUuXLknNmWeeWd2NUeywww7J2umnnx7k//znP0nNbrvtFuSywcu9evX6yFwURdG1a9cgr1y5MqmJ7yC0b98+qYn/Vpb97WzK7/nWwBNAAIDMaAABADKjAQQAyIwGEAAgMy6BNKGxY8cGeYsttqj4mjvvvDNZu/rqq6u2J6rr+OOPT9a+973vBbl///5JTdu2bYP89NNPJzXjx48P8rRp0xqzRVq5Y445Jshlv0d++tOfBvmuu+6q5ZYqOu2004JcdgFu5syZQXbhoza22267IJddyOnXr1+QP/jgg6SmTZvw+dGWW26Z1GzcuDHIGzZsqLi/999/P1l77733ghxfHCmK8oshsXhYdO48AQQAyIwGEAAgMxpAAIDMOANYIz/+8Y+Ttb59+1Z83Zw5c4IcD32l+Rx99NHJWvzh4mXDUOOhzvPmzUtq4uHQl19+eWO2yCbmC1/4QrK26667BrnsfNZNN91Uqy01Svyzs2DBgqTmoosuaqrtZO3BBx8McjzQuSiKolOnTkEuO2e6evXqIL/44otJzd///vcgP/HEE0nNm2++GeR33nknqbn00kuDfNRRRyU1nTt3DnLZeb+FCxcmaznzBBAAIDMaQACAzGgAAQAyowEEAMiMSyBV0qdPnyBfcMEFFV+zdu3aZC1+3ZIlSz7ZxqiaKVOmNOp18TDUsn/3e++9t1HvXSu77LJLkOPhw2U1kydPTmqeeeaZIH/6059OasqGXvO/hgwZkqzFB/IXL16c1Lz++us121Ml8YH9oiiKHj16BHnixIlJzUMPPVSzPeXqW9/6VrK25557BnnlypVJzd133x3kZ599Nql59NFHgzx16tRG7LBhHnvssSAPHjw4qamrqwty2f+upUuXVndjrZwngAAAmdEAAgBkRgMIAJAZZwCr5Morrwxyhw4dkpr6+vog33///UnNfffdV9V9UT3r1q1L1uIPIF+zZk1S065d+GMWn4cqiqI455xzglx23nDUqFFB/u9//5vUxGdGy87cHXzwwUGOB1UXRfng10p+8IMfJGvx+cf4A+TLlA3KnjZtWpDPPvvsj7m71mnnnXdO1rbccssgz58/v2k2UxTFiBEjkrV4KO+BBx6Y1MSDzsvOAFJ9b7/9dsWa1157LVmLfx+V/a5pSm3btg1y2ZDnWNkZwLLz1znzBBAAIDMaQACAzGgAAQAyowEEAMiMSyCNMGbMmGRt4MCBQY6HUhZFekD/9NNPr+7GqKnHH388Wdtxxx2D3LNnz6QmvvhQduni1FNPDXLZANeG2LBhQ5Djw9NFkV5UefLJJ5Oa+Hu1a9euSc2KFSuCXHZ5I37d9ttvn9TEA6Xjy1JFURQDBgwIcnzxoChqO4i2ucT/bYoivXhUS/FA4F69eiU18aWU6dOnJzUTJkyo6r5omLLh7PHFrJkzZyY1zX3pI3bYYYcFuewiXWz27NnJ2oMPPlitLW0SPAEEAMiMBhAAIDMaQACAzDgD2AD77LNPkK+44oqKr1m2bFmydvHFFwe5IUM6aTniAcpFURTjx48P8qBBg5Ka+Bxe2ZDl+Ozg1ltvndQ0ZPhpfPa0bDD1//zP/wT5V7/6VcX3pXk8+uijyVr8vbL33nsnNfHZr6eeeiqp6d27d5BPOeWUivt54IEHkrUFCxYEeeTIkRXfh+azfPnyIJedE25OZb+Phg0bVvF1s2bNCvL5559frS1tsjwBBADIjAYQACAzGkAAgMxoAAEAMlNXXzZ1taywZLBxLiZOnBjkb3/720lN/J+x7IJHPDSYPO21117J2pAhQ4K82WabJTX77bdfkP/5z38mNb///e+DHA90pvWbMWNGkA855JCkZtWqVUEuuwzUqVOnIHfo0CGpiYd9X3fddUnNBRdc8OGbpcWJ/1Z98MEHSc0xxxwT5LLfNY0xadKkZO3EE08M8lZbbVXxfZ577rlkbd999w3y+vXrP+buNh0NbOs8AQQAyI0GEAAgMxpAAIDMGATdAP37969Ys2HDhiA/++yzNdoNrd2LL77YoDUoc8011wS5bGh4fN44Pu9XFOkA4LIhz+eee26QX3nllQbvk5Zpzpw5Qe7evXtSc/311wd5ypQpFd+nW7duSc3gwYODXDYov+x7M/bEE08EOT4PTeN4AggAkBkNIABAZjSAAACZ0QACAGTGIOjIsccem6zFwyvbtEn75n/84x9BHjlyZFX3BQDVduGFFyZrZ5xxRpC7du2a1Kxbty7I7du3T2rigfZlNbHLLrssWfvRj35U8XX8PwZBAwBQSgMIAJAZDSAAQGacAYyUfdj50KFDg/ynP/0pqRk9enTN9gQATWX33XcPctm5vGHDhgU5Pu9XFEWxevXqIN94441Jzfjx44O8ZMmShm6TD+EMIAAApTSAAACZ0QACAGRGAwgAkBmXQCK33357srZq1aogn3zyyU21HQBoceJLH9tss01Ss3jx4iCvXLmypnvif7kEAgBAKQ0gAEBmNIAAAJlxBjDSvXv3ZG3p0qXNsBMAgI/HGUAAAEppAAEAMqMBBADIjAYQACAzLoEAAGwiXAIBAKCUBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzGgAAQAyowEEAMiMBhAAIDMaQACAzLRr7g3w0XbddddkbeDAgUHu0qVLUvP4448H+fnnn6/qvgCA1ssTQACAzGgAAQAyowEEAMiMM4DN6OCDD07WLr300iAPGDAgqWnXLvxn69ixY8WvNWfOnGStb9++FV9Hy9WzZ89k7eabbw7y4MGDm2o7ALQingACAGRGAwgAkBkNIABAZjSAAACZcQmkCQ0bNizIP/3pTyu+5u67707W4ksfn//855OaTp06BXnzzTdvyBZpRQYNGpSsxReLli5dmtSMGTMmyNdff311NwZAi+cJIABAZjSAAACZ0QACAGSmrr6+vr5BhXV1td7LJm/69OlBbtMm7b8POeSQj/2+kyZNStZGjhwZ5GXLliU1u+yyy8f+WrRs8+fPD/KOO+6Y1MybNy/Iffr0qeWWAGhCDWzrPAEEAMiNBhAAIDMaQACAzGgAAQAyYxB0E1q8eHGQL7nkkqq8bzwYuiiKom3btkFu6KFQWrfbbrstyGeffXZSs8ceewT52GOPTWruuuuuam4LaEUGDBgQ5DPPPDOpueaaa4L89NNP13RPVJ8ngAAAmdEAAgBkRgMIAJAZZwCb0PHHH1+T9y073xcPmX7jjTdq8rVpWbbffvsgr1q1Kqnp1KlTkPv165fUOAMI+Ro7dmyQhw4dmtQMGjQoyC+//HJSs2TJkiCvXLkyqYk/kCA+K18URbFhw4Ygb7755knNokWLKu5n2rRpQX711VeTmpx4AggAkBkNIABAZjSAAACZ0QACAGTGJZBNQHxAtiiKYt26dUG+++67m2o7NKMOHToEef369RVfc8QRRyRrF198cdX2ROsVfz+tXbs2qendu3eQ586dW9M9/f8uv/zyZK1bt25BLrsw0L1794rv/Z3vfCfI8+fP/3iba8WuuuqqIPfo0SOpiYdFxwPmG+u9995L1tq1C1uV+IMOiiK93Pbuu+8mNaNGjQryrFmzkpoXXnghyBMmTPjwzbZyngACAGRGAwgAkBkNIABAZpwB3ATstNNOyVo8CHrnnXduqu3QjLbbbrsgd+zYMamJz88sW7aslluilRg9enSydvrppwf5jjvuSGpuueWWmu0pdsUVVwT57LPPTmric4vt27dPaqZPnx7kyZMnJzU5nfmLzZgxI8iDBw9OauIBzgcccEBSE58LXLNmTVIzb968IJf9d4/fp66uLqmJ9zhkyJCkZt999/3IXBRFMXv27CDX8gxg/Pu6c+fOSU3836eaPAEEAMiMBhAAIDMaQACAzGgAAQAy4xJIK3T++ecHeb/99ktq4oP+e++9dy23RAux2WabfWQu8+yzz9ZoN7Qm8e+VokgHP//ud79LahYsWFCT/YwYMSJZO+ecc4K8dOnSpOaSSy4J8uOPP57UvPjii59wd7z++usfmavpiSeeqFhz8803B/moo45Kan70ox8FuX///klN2eDwWnnnnXea7GuV8QQQACAzGkAAgMxoAAEAMuMMYCv01a9+Nchbb711UrNy5cogL1y4sKZ7omXo0qVLkMuG4G7cuLFiDZu+X//610GOzw0XRToEt1bn/YqiKC6++OIgjxo1Kqm59957g/zLX/4yqXnyySeruzFapalTpyZr3bt3D3L8M1AURdG1a9ea7aml8QQQACAzGkAAgMxoAAEAMqMBBADIjEsgLdw222yTrPXo0SPIGzZsSGrWrVsX5CVLllR3YzS70047LVmLDzCXHeyPB7b+4x//qO7GaHHGjh2brMXfP2VDnq+55pqqfP0LLrggyN/+9reTmkWLFgV54sSJSU3ZpQ9oqDVr1gS5Q4cOSU08PP+UU05Jam666abqbqyZeAIIAJAZDSAAQGY0gAAAmXEGsIXbf//9k7VOnToFecWKFUlNfC5wt912q+7GWpGys3LDhw8PctnZopdffjnIq1atSmri85jxh9UXRVHsuOOOQS4bvBwP7u7WrVtSE38vlA0sbdeu8o90/L3xwAMPVHwNrcvAgQODfOqppyY1y5cvD/KLL75Yla99zz33JGtDhgwJ8q233prUjBw5sipfH4qiKPbcc89k7fLLLw9yPDi/KNLfj5dccklS4wwgAACtkgYQACAzGkAAgMxoAAEAMlNXX19f36DCurpa76XV+OIXv5isHX744UGePXt2UjNlypQgf+5zn0tqTjrppCAfdNBBSU3Pnj2DXDbs98033wzyH/7wh6TmoosuStY2RTvssEOy9vzzzwe5c+fOSc3q1asrvnc8SLQh77Nx48akJv4xLPs3jQeUNvZncs6cOUHu27dvo96HlmHEiBHJ2tVXXx3ksoHy77//fpDLLjm98sorQd5jjz2Smvji0ZZbbpnUxN/Ps2bNSmpuv/32IE+aNCmpWbhwYbJGfvr06ZOs/exnPwvygAEDkpr40l5DLs0tW7YsWXv44YeDXPb3Nf5+bkoNbOs8AQQAyI0GEAAgMxpAAIDMtNozgPFw3fjDxj9srTHOPffcIA8bNiypiQf3zp8/P6nZddddg1x2VmannXYKctl5sfjfouys2nXXXRfkcePGJTU5e+SRR4Icnw0piqL497//HeTevXsnNfFa2ZDn2HvvvZesxf+m8TDSoki/XxryM7l+/fpkLT4DuPfee1d8H1qOz372s0G+4YYbkpp+/foFee7cuUlNfG7pL3/5S1Jz1llnBfm8885LauJzsI21aNGiIL/22mtJTXxusex36Jo1a4L897//PakpG+5Ly1A2uP/YY48N8u67757UxH9fy873lZ2trqSsRYp/h8d/T4oiHX7elJwBBACglAYQACAzGkAAgMxoAAEAMtNqL4HEgxjLDncOHDiwqbZTNSeccEKQyy6y9O/fP8gPPfRQUvPlL385yEuXLq3C7ojFh9AHDx6c1Pztb38LctnA3fjyT9lB6Hhwd2N/JseMGRPkn//85416H2ov/jkuivQCw7bbbpvU/OIXvwhyPCS3oYYPHx7km2++OanZYostghxfMiqKorjiiiuCfOuttyY1a9eurbifXXbZJcjvvvtuUhNfFKH5HHLIIUGOL3MURfqBCPvtt19SUzZgvxrK/i7+5z//CfLTTz+d1Fx55ZVBfu6556q6r0/KJRAAAEppAAEAMqMBBADITOVPQm6h4g8lv+OOO5ppJ9U1derUIJ955plJTXyG7L777ktqnPlrGvEHhf/1r39t1PvE504uvvjipCY+03rkkUdWfN+ysyCPPvrox9wdzaXsfGZ8Du6cc85JauJB8I01dOjQIMfn/YqiKGbMmBHkE088Mal56623qrKf119/vSrvw0eLh8OXnafff//9g9ynT5+kJh6Uv8MOO1Rhd0Xx3//+N1mLz5kuX748qRk0aFCQJ0+enNTcc889n3B3rYcngAAAmdEAAgBkRgMIAJAZDSAAQGZaxSWQgw8+OFmLD9+/8cYbTbSb2jrllFOCHB+iLYqieOSRR4I8YcKEmu6JluG4444LcnxxpCiKYuuttw7ymjVrkpp4kPjMmTOrsDtq4e23365YU/ZvHA/T3bBhQ1ITf6+UDZ3+/Oc/H+SyyyVlF9Voub7yla8EuWzo/IEHHhjksg9a2GyzzSp+rfXr1wd59erVSU2nTp2CXDYQfP78+UH+05/+lNRcffXVFfdz0003VazJiSeAAACZ0QACAGRGAwgAkJlWcQaw7MPO43Mvzz77bBPtpnpOOOGEZO28884LcnxOpyiK4tJLLw1yfM6CTVP8PT9lypSkZsSIEUEuG9z7ta99LcjxB5vTchx66KHJ2llnnRXk4cOHJzWXXHJJkDfffPOkJv5+6tGjR1Ize/bsIDvv1/rFA5N79epV8TVlZ0gXLlwY5HXr1iU1Xbp0CXKHDh0qfq3Fixcna+PGjQvy7bffXvF9qMwTQACAzGgAAQAyowEEAMiMBhAAIDOt4hJIPPi4KNLD7WXDI1u6sgGcPXv2DPKrr76a1Pz+97+v2Z5oPb75zW8max07dgzy0KFDk5o99tgjyKeeempSc8MNN3zC3VENZRe84oG3ZQNwzzjjjCB//etfT2rigeDvvvtuUlM2cJfW7YUXXqhYEw+Zf+mll5Kap556Kshlf4NHjRoV5L59+yY17du3D/K1116b1Lj0URueAAIAZEYDCACQGQ0gAEBm6urr6+sbVFhXV+u9fCxz584N8vvvv5/U7LPPPk20m4b585//HOT4g9aLoij+9a9/BbnsfNaSJUuquzE2WVOnTk3WDjvssIqvmzFjRpC//OUvJzUrVqxo9L5oWmUDpeNzVfHv1KIoiv33379me6Jl6N27d7JW9r1QDRMmTEjW7r///iCX/c7i42lgW+cJIABAbjSAAACZ0QACAGRGAwgAkJlWMQi6THyA+aCDDkpqpk+fHuRtt902qenatWuQZ82aldS88847Qd5qq62Smm222SbIZQdrR48eHeSyYbvTpk1L1qCx4sscRVEU/fr1C/J2222X1AwcODDIt912W1ITDxdetmxZI3ZIU3jjjTeStTVr1gT5ySefbKrt0ILU6sJHmcceeyxZc+mj+XgCCACQGQ0gAEBmNIAAAJlptYOgG2L27NlB3n333ZOatm3bBvnNN99Matq0Cfvk7t27JzVvvfVWkGfOnJnUnHzyyR++WWgiv/zlL4N85plnJjWdO3cOctmg9VtuuSXI5557bhV2Ry2MHTu24tr555+f1Nx000212hJQIwZBAwBQSgMIAJAZDSAAQGY0gAAAmdmkL4HE4sscRVEUw4cPD/KiRYuSmmeeeSbIK1asqO7GoBndeuutydqJJ55Y8XWvvPJKkI844oikpmwAMQC14xIIAAClNIAAAJnRAAIAZCarM4BAwxx22GFB3muvvZKaUaNGBXn8+PFJzbRp06q6LwA+mjOAAACU0gACAGRGAwgAkBkNIABAZlwCAQDYRLgEAgBAKQ0gAEBmNIAAAJnRAAIAZEYDCACQGQ0gAEBmNIAAAJnRAAIAZEYDCACQGQ0gAEBmNIAAAJnRAAIAZEYDCACQGQ0gAEBmNIAAAJnRAAIAZEYDCACQGQ0gAEBmNIAAAJnRAAIAZEYDCACQGQ0gAEBmNIAAAJnRAAIAZEYDCACQGQ0gAEBm2jW0sL6+vpb7AACgiXgCCACQGQ0gAEBmNIAAAJnRAAIAZEYDCACQGQ0gAEBmNIAAAJnRAAIAZEYDCACQmf8DqgXcQbVritgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y1yy5-gKkCCQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}